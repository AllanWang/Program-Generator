%
% File naaclhlt2016.tex
%

\documentclass[11pt,letterpaper]{article}
\usepackage{naaclhlt2016}
\usepackage{times}
\usepackage{latexsym}

% \naaclfinalcopy % Uncomment this line for the final submission
\def\naaclpaperid{***} %  Enter the naacl Paper ID here

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

\newcommand\BibTeX{B{\sc ib}\TeX}


\title{Program Generation from Natural Languages}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
% \author{Margaret Mitchell \and Adam Lopez\\
  % {\tt naacl-pub-chairs@googlegroups.com}}

% https://github.com/acl-org/acl-pub/blob/gh-pages/paper_styles/archive/naaclhlt2016-latex/naaclhlt2016.pdf
\author{Allan Wang \and Youngsun Jin \\
        McGill University \\ \tt{\{allan.wang,youngsun.jin\}@mail.mcgill.ca}}  
\date{}

\begin{document}

\maketitle

\begin{abstract}
  When learning new programming languages, it is often easy to understand the syntax and learn
  about idiomatic executions through examples. Particularly with different paradigms, how we
  write code in one language may not be one to one with code in another language. Most
  languages provide examples through a list of common executions. If we can instead provide an
  example matching simple instructions in English, we can help refine the amount of code
  a new developer has to go through, and assist in creating an infinite set of examples tailored to
  each user. In this work, we have developed a prototype system which is able to process natural language instructions
  related to list creation with optional conditions, which is then translated into executable code with programming language provided by the user.
\end{abstract}

\section{Introduction}
Learning the syntax of a programming language can be frustrating and challenging. 
For a new developer, programming languages contain lots of domain-specific rules, varying in control structures, syntax, etc.
For experienced developers, programming languages may introduce completely new paradigms, and may not be easily translated from known languages through one to one mappings of keywords.
One way to help overcome this technical hurdle is to read official documentation, or a large set of common examples.
However, this is often a big time investment for a user who just wants to explore the basics of a language.
Moreover, the examples may not completely reflect the desired use case, and can often be irrelevant to the problem at hand.

Our goal is to explore the feasibility of mapping natural languages to programs by extracting features and creating runnable code.
This would greatly reduce the learning curve when dealing with simple operations, and will help introduce language features without the developer knowing about them beforehand.
More specifically, we wish to focus on generating number lists in multiple programming languages, allowing for varying constraints available across all supported languages.
We will use Combinatory Categorial Grammar (CCG) to create a tree representing the logic, then introduce language specific transformers to map subtrees to working code.
Lastly, we will pass through the generated body and output a working program.
On top of being able to create a program, we wish to introduce a structure that can be extended to support both new languages and new operations within the semantics tree.

% TODO should we give an example?
% Main goal of intro is to have the hypothesis, which is above   

\section{Related Work}

\subsection{Natural Language to Database Query}

One of the earliest system that makes use of natural language translation into executable code is a Natural Language Interface
for a Database (NLIDB) (Androutsopouloset al., 1995). When databases contain an enormous number records, a specific query language such as the Structured Query Language (SQL) needs to be used in order to extract specific records specified by the expert user. This means that one needs to understand the syntax for querying the database and the way to join the underlying tables to extract necessary records. However, this introduces difficulties for users because they may not be aware of the structure of the database. A NLIDB simplifies the task by providing the user interface to input natural languages to query the database. We can clearly see how this is similar to our task. We want to take natural language as an input, and output equivalent executable code in the user-specified language which returns a collection of entities with some conditions specified by the user. For feasibility, we have simplified the problem to creating a list of numbers with conditions that can be applied to each number inside the list.   

\subsection{Natural Language to Java}
NaturalJava (Price et al., 2000) is one of the early systems that 
allows to create Java programs from English commands. The system accepts English sentences as input and then uses information extraction techniques to map one of 400 case frames. Then the interpreter infers changes that have to be made using a decision tree, which then manipulates Java abstract syntax tree (AST). The AST is automatically converted into Java source code. Although our task is similar in a sense that both translate natural language into code, we do not manually create case frames to infer programs. Our task is more involved with parsing the natural language sentence using a set of rules to generate semantic representation of the input.

\subsection{Unrestricted Natural Language}
One of the most powerful natural language interface was developed (David et al., 2006). They presented the prototype system which takes unrestricted English as input and output code in the Python programming language. They used Combinatory Categorial Grammar (CCG) as a base tool to generate syntactic categories for English sentences. Then the \textit{ccg2sem} system (Bos et al., 2004; Black-burn and Bos, 2005) was used to convert CCG parse trees into Discourse Representation Structure (DRS). Having extracted the functional verb and its arguments, if the semantic information matches with predefined primitives, then the equivalent code is generated. Unlike our task, they trained the new model for the parser on the manually-generated corpus as a result of the differences between standard English sentences and programming statements. However, in this work, we predefined the set of rules in CCG to assign each word with functional feature instead of syntactic category, which will be then used to generate the semantic representation of the whole sentence.

\section{Methodology}

\begin{figure*}[t]
  \small
  \begin{verbatim}
            list                  from         0         to          100
((L/RF)/RT) {\y x.list(x,y)}  (RF/I) {\x.x}  I {0}  (RT/I) {\x.x}  I {100}
                              ---------------------->
                                      RF {0}
                              ----------------------<T
                              (L\(L/RF)) {\F.F(0)}
----------------------------------------------------<B
              (L/RT) {\y.list(0,y)}
                                                    ------------------------>
                                                            RT {100}
---------------------------------------------------------------------------->
                              L {list(0,100)}
  \end{verbatim}
  \caption{\label{font-figure} Shortened example of CCG output.}
\end{figure*}

\subsection{CCG Parsing}

In creating our grammar, we defined a set of rules for each type we may encounter. 
We have the following primitives: {\small\verb|program|}, {\small\verb|creation|}, and {\small\verb|range|}.
A program represents an independent set of rules that is capable or defining a runnable program.
A creation denotes a rule that generates new data. 
This can be any viable programming type, but in our case specifically, it represents an integer list.
A range represents a phrase with a minimum number and maximum number.
This is necessary in creating a proper list.

For conditions, we can create higher order types that build upon existing lists.
For instance, an `even list from 0 to 100' would still represent ths {\small\verb|list|} primitive, with a new feature attached.
Here, we begin to face some problems.
We can for instance want a `list from 0 to 100 that is divisible by 4', but a `divisible by 4 list from 0 to 100' would not make sense.
We can work around this by introducing special groups per condition, and making sure that our program rules respect the expected groups based on the order of the initial sentence.

Another problem we face is supporting number parsing, where a number primitive can be any valid sequence of digits. 
One way we considered was post processing, where we would replace each number with a special symbol, create our tree, then add back the numbers in the same order as they appeared in the sentence.
This poses a problem, as our assumption of word order may not always be correct. As an example, both `create a list from 0 to 100' and `create a list to 100 from 0' are represented by the same tree, and yet the numbers are not in the same order.
We worked around this by extracting all the numbers in the word token, adding rules that map them to the same integer primitive, and then creating a new ccg parser for each sentence.

The final result allows us to create CCGs like in figure 1.
\subsection{Language Formatting}

As we wish to parse our input using a CCG, we must first ensure that our corpus is contained in our lexicon.
We can simply do so be removing all words that are not part of our lexicon, but that would greatly constrain our input, and may also result in code that does not represent what we wanted.
To support a wider set of tokens, we will preprocess the text with a dictionary of token words to NLTK lemma keys.
We can use the keys to extract synonyms, and provided that each word is unique to a specific token, we can replace them without altering the semantics.

We still need to filter out the remaining words, but in checking the part of speeches, we noted that condition features typically contain an adjective or adverb.
We can therefore filter out words without those part of speeches, and return an error when other unknown tokens are found.
This allows us to parse instructions beyond the keywords that we select, and allows us to reject inputs that we cannot parse with reasonable confidence.

\subsection{Feature Mapping}

Once we have our semantics tree, we can map them into programming rules.
By the way we defined our primitives, it is noted that each node can lead to a part of a programming with the information within its subtree.
As we are familiar with both the number of children per primitive, as well as their orders, we can create code templates that take in child subcomponents and generate a new subcomponent.
Once we get to the program primitive, the result should be a working program.

\subsection{Code Generation}

Given that our feature mapping aims to convert a semantics tree to code, our code generation is essentially applying our feature map to the root node.
However, the process is not so simple.
A common part of many programming languages is a set of import rules at the top of the file.
While we can add each rule in our template if they don't appear elsewhere in the subtree, this can quickly become messy for large trees.
A simpler method is to aggregate all necessary imports, and to post process our code to ensure we add unique imports.
We did so by introducing a variable in our feature map output, so that each token is mapped to both a template and an import set.

It is worth noting that method is quite extensible, as it does not affect the generation of our program body.
We can almost view it as a new feature tree, where we can define a new mapping to further convert it into code.
In the case of imports, the mapping per node is to simply aggregate the unique key set and to output each of them in a new line.

\subsection{Negation Extension}

To test the extensibility of our implementation, we implemented negation using our existing structure.
We may note that a negation can take place before any existing condition, and will result in a new predicate with the opposite output.
Furthermore, as an optimization, two consecutive negations will cancel out. 
While we could preprocess the text and remove consecutive negations, we decided to handle this within the parse tree.
To support the negation feature, we will add another attribute in our feature map for conditions only.
When we encounter a negation feature in our tree, we will simply take the child and flip the negation field.
Note that this does mean that we have to apply our template function lazily, as we can only be sure of a condition's negation after the full sentence is parsed.

\pagebreak
~
\pagebreak

\textbf{References}:  We recommend
including references in a separate~{\small\texttt .bib} file, and include an example file 
in this release ({\small\tt naalhlt2016.bib}).  Some commands
for names with accents are provided for convenience in Table \ref{tab:accents}.  
References stored in the separate~{\small\tt .bib} file are inserted into the document using the following commands:

\small
\begin{verbatim}
\bibliography{naaclhlt2016}
\bibliographystyle{naaclhlt2016}
\end{verbatim}
\normalsize 

References should appear under the heading {\bf References} at the 
end of the document, but before any Appendices, unless the appendices contain references.  
Arrange the references alphabetically
by first author, rather than by order of occurrence in the text.  %This behavior is provided by default in the provided \BibTeX\ style ({\small\tt naaclhlt2016.bst}). 
Provide as complete a reference as possible, using a consistent format,
such as the one for {\em Computational Linguistics\/} or the one in the 
{\em Publication Manual of the American 
Psychological Association\/}~\cite{APA:83}.  Authors' full names rather than initials are preferred.  You may use
{\bf standard} abbreviations for conferences\footnote{\scriptsize {\tt https://en.wikipedia.org/wiki/ \\ \-\hspace{.75cm} List\_of\_computer\_science\_conference\_acronyms}} and journals\footnote{\tt http://www.abbreviations.com/jas.php}.




{\bf Appendices}: Appendices, if any, directly follow the text and the
references (but see above).  Letter them in sequence and provide an
informative title: {\bf Appendix A. Title of Appendix}.

\textbf{Acknowledgment} sections should go as a last (unnumbered) section immediately
before the references.  


\subsection{Footnotes}

{\bf Footnotes}: Put footnotes at the bottom of the page. They may
be numbered or referred to by asterisks or other
symbols.\footnote{This is how a footnote should appear.} Footnotes
should be separated from the text by a line.\footnote{Note the
line separating the footnotes from the text.}  Footnotes should be in 9 point font.

\subsection{Graphics}

{\bf Illustrations}: Place figures, tables, and photographs in the
paper near where they are first discussed, rather than at the end, if
possible.  Wide illustrations may run across both columns and should be placed at
the top of a page. Color illustrations are discouraged, unless you have verified that 
they will be understandable when printed in black ink. 

\begin{table}
\small
\centering
\begin{tabular}{|l|rl|}
\hline \bf Type of Text & \bf Font Size & \bf Style \\ \hline
paper title & 15 pt & bold \\
author names & 12 pt & bold \\
author affiliation & 12 pt & \\
the word ``Abstract'' & 12 pt & bold \\
section titles & 12 pt & bold \\
document text & 11 pt  &\\
abstract text & 10 pt & \\
captions & 9 pt & \\
caption label & 9 pt & bold \\
bibliography & 10 pt & \\
footnotes & 9 pt & \\
\hline
\end{tabular}
\caption{\label{font-table} Font guide.}
\end{table}

{\bf Captions}: Provide a caption for every illustration; number each one
sequentially in the form:  ``{\bf Figure 1:} Figure caption.'', ``{\bf Table 1:} Table caption.''  Type the captions of the figures and 
tables below the body, using 9 point text.  Table and Figure labels should be bold-faced.

\subsection{Accessibility}
\label{ssec:accessibility}

In an effort to accommodate the color-blind (as well as those printing
to paper), grayscale readability for all accepted papers will be
encouraged.  Color is not forbidden, but authors should ensure that
tables and figures do not rely solely on color to convey critical
distinctions.

\section{Length of Submission}
\label{sec:length}

The NAACL HLT 2016 main conference accepts submissions of long papers and short papers.  Long papers may consist of up to eight (8) pages of content, plus unlimited pages for references. Upon acceptance, final versions of long papers will be given one additional page (up to 9 pages with unlimited pages for references) so that reviewers' comments can be taken into account.  Short papers may consist of up to four (4) pages of content, plus unlimited pages for references. Upon acceptance, short papers will be given five (5) pages in the proceedings and unlimited pages for references.  For both long and short papers, all illustrations and appendices must be accommodated within these page limits, observing the formatting instructions given in the present document.  Papers that do not conform to the specified length and formatting requirements are subject to be rejected without review.


\section{Double-blind review process}
\label{sec:blind}

As the reviewing will be blind, the paper must not include the
authors' names and affiliations.  Furthermore, self-references that
reveal the author's identity, e.g., ``We previously showed (Smith,
1991) ...'' must be avoided. Instead, use citations such as ``Smith
previously showed (Smith, 1991) ...'' Papers that do not conform to
these requirements will be rejected without review. In addition,
please do not post your submissions on the web until after the
review process is complete (in special cases this is permitted: see 
the multiple submission policy below).

We will reject without review any papers that do not follow the
official style guidelines, anonymity conditions and page limits.

\section{Multiple Submission Policy}

Papers that have been or will be submitted to other meetings or
publications must indicate this at submission time. Authors of
papers accepted for presentation at NAACL HLT 2016 must notify the
program chairs by the camera-ready deadline as to whether the paper
will be presented. All accepted papers must be presented at the
conference to appear in the proceedings. We will not accept for
publication or presentation papers that overlap significantly in
content or results with papers that will be (or have been) published
elsewhere.

Preprint servers such as arXiv.org and ACL-related workshops that
do not have published proceedings in the ACL Anthology are not
considered archival for purposes of submission. Authors must state
in the online submission form the name of the workshop or preprint
server and title of the non-archival version.  The submitted version
should be suitably anonymized and not contain references to the
prior non-archival version. Reviewers will be told: ``The author(s)
have notified us that there exists a non-archival previous version
of this paper with significantly overlapping text. We have approved
submission under these circumstances, but to preserve the spirit
of blind review, the current submission does not reference the
non-archival version.'' Reviewers are free to do what they like with
this information.

Authors submitting more than one paper to NAACL HLT must ensure
that submissions do not overlap significantly ($>25\%$) with each other
in content or results. Authors should not submit short and long
versions of papers with substantial overlap in their original
contributions.

\section*{Acknowledgments}

Do not number the acknowledgment section.

\bibliography{naaclhlt2016}
\bibliographystyle{naaclhlt2016}


\end{document}
